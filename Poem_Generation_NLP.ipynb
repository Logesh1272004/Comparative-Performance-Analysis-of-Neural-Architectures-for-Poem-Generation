{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1648795,
          "sourceType": "datasetVersion",
          "datasetId": 974990
        }
      ],
      "dockerImageVersionId": 30527,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'poemsdataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F974990%2F1648795%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240322%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240322T082153Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D46cf03a9cf31cbd96f47b33847f5b4913d2052d6df07553a22e10c88d185cbd291f94e4cc1d90cbc2c49b211c8790f31a440d7f7d555e6f540caabbe3a1ed2449cf946c5d7172f98e94d6472e5d810d7f1fdc26c8874dc819cfddd5a6d728205fa26a4d10796715ce98ac2698357921319f98fbeabfd315d244e092302b3326f883171fec2d17b1554e9c9d5aeb348f0c57e4dc08071c3130dd3ea9a905cd033ce9d632ca4b2f71d3479e614dd6756e70f6b8e54476ed6109a37a33db5da47fbb61cf8e67e4461deeae03f6028eeb591f9f8d023cb6aa628068b08f8d49cecdfc9b785f5e157919ca7d67c34b144a2ff8117818c8cdd61a74686a164e34e9efa'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "LITtrDY_TgD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "103d9c67-6332-4513-f9e0-17a3c62bd921"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading poemsdataset, 16279790 bytes compressed\n",
            "[==================================================] 16279790 bytes downloadedFailed to load https://storage.googleapis.com/kaggle-data-sets/974990/1648795/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240322%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240322T082153Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=46cf03a9cf31cbd96f47b33847f5b4913d2052d6df07553a22e10c88d185cbd291f94e4cc1d90cbc2c49b211c8790f31a440d7f7d555e6f540caabbe3a1ed2449cf946c5d7172f98e94d6472e5d810d7f1fdc26c8874dc819cfddd5a6d728205fa26a4d10796715ce98ac2698357921319f98fbeabfd315d244e092302b3326f883171fec2d17b1554e9c9d5aeb348f0c57e4dc08071c3130dd3ea9a905cd033ce9d632ca4b2f71d3479e614dd6756e70f6b8e54476ed6109a37a33db5da47fbb61cf8e67e4461deeae03f6028eeb591f9f8d023cb6aa628068b08f8d49cecdfc9b785f5e157919ca7d67c34b144a2ff8117818c8cdd61a74686a164e34e9efa to path /kaggle/input/poemsdataset\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import *"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-08-27T10:19:21.225983Z",
          "iopub.execute_input": "2023-08-27T10:19:21.226381Z",
          "iopub.status.idle": "2023-08-27T10:19:21.234004Z",
          "shell.execute_reply.started": "2023-08-27T10:19:21.226348Z",
          "shell.execute_reply": "2023-08-27T10:19:21.232832Z"
        },
        "trusted": true,
        "id": "nWA3miv2TgED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"/kaggle/input/poemsdataset/topics\"\n",
        "corpus = []\n",
        "corpus_size = 10000\n",
        "done = False\n",
        "\n",
        "print(\"Loading poems in corpus...\\n\")\n",
        "for dirname, _, filenames in os.walk(root_dir):\n",
        "    if done: break\n",
        "    print(f\"Loading {dirname}\")\n",
        "    for filename in filenames:\n",
        "        if done: break\n",
        "        with open(os.path.join(dirname, filename), \"r\") as file:\n",
        "            txt = file.read()\n",
        "            for line in txt.split(\"\\n\"):\n",
        "                if done: break\n",
        "                corpus.append(line)\n",
        "                if len(corpus) == corpus_size:\n",
        "                    done = True"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:19:21.238745Z",
          "iopub.execute_input": "2023-08-27T10:19:21.239044Z",
          "iopub.status.idle": "2023-08-27T10:19:21.46034Z",
          "shell.execute_reply.started": "2023-08-27T10:19:21.239011Z",
          "shell.execute_reply": "2023-08-27T10:19:21.459327Z"
        },
        "trusted": true,
        "id": "rKUuUgepTgEG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb32c72-8143-435f-88f8-e787f282e6a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading poems in corpus...\n",
            "\n",
            "Loading /kaggle/input/poemsdataset/topics\n",
            "Loading /kaggle/input/poemsdataset/topics/frog\n",
            "Loading /kaggle/input/poemsdataset/topics/money\n",
            "Loading /kaggle/input/poemsdataset/topics/paris\n",
            "Loading /kaggle/input/poemsdataset/topics/city\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpus)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:19:21.46326Z",
          "iopub.execute_input": "2023-08-27T10:19:21.463615Z",
          "iopub.status.idle": "2023-08-27T10:19:21.472854Z",
          "shell.execute_reply.started": "2023-08-27T10:19:21.463582Z",
          "shell.execute_reply": "2023-08-27T10:19:21.471592Z"
        },
        "trusted": true,
        "id": "kJr68gf5TgEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d5faef-369c-41d7-9f7a-57d359bef4a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[:10]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:19:21.474481Z",
          "iopub.execute_input": "2023-08-27T10:19:21.475793Z",
          "iopub.status.idle": "2023-08-27T10:19:21.483825Z",
          "shell.execute_reply.started": "2023-08-27T10:19:21.475756Z",
          "shell.execute_reply": "2023-08-27T10:19:21.482623Z"
        },
        "trusted": true,
        "id": "IKRShu-STgEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0235c3d-2b10-4233-e630-7e68d191962e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I have a pet frog',\n",
              " 'We go frog walking every day at 6pm',\n",
              " 'He is fine until he sees another frog',\n",
              " 'He sniffs & then tries to jump',\n",
              " 'I pull him away',\n",
              " 'Last week we had a problem',\n",
              " 'My frog stopped to do his business',\n",
              " 'A passer bye said stop your frog fouling',\n",
              " 'I cleared up after him but it left a slimy mark',\n",
              " 'The other man slipped on it']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punc(s):\n",
        "    return s.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "corpus = [ remove_punc(s.lower().strip()) for s in corpus ]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:19:21.487238Z",
          "iopub.execute_input": "2023-08-27T10:19:21.48806Z",
          "iopub.status.idle": "2023-08-27T10:19:21.533494Z",
          "shell.execute_reply.started": "2023-08-27T10:19:21.488033Z",
          "shell.execute_reply": "2023-08-27T10:19:21.532589Z"
        },
        "trusted": true,
        "id": "HaK0alABTgEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[:10]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:19:21.534962Z",
          "iopub.execute_input": "2023-08-27T10:19:21.535328Z",
          "iopub.status.idle": "2023-08-27T10:19:21.543224Z",
          "shell.execute_reply.started": "2023-08-27T10:19:21.535296Z",
          "shell.execute_reply": "2023-08-27T10:19:21.540836Z"
        },
        "trusted": true,
        "id": "67P_k-SGTgEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a79f6b-bc92-4af3-9019-84545846f44c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i have a pet frog',\n",
              " 'we go frog walking every day at 6pm',\n",
              " 'he is fine until he sees another frog',\n",
              " 'he sniffs  then tries to jump',\n",
              " 'i pull him away',\n",
              " 'last week we had a problem',\n",
              " 'my frog stopped to do his business',\n",
              " 'a passer bye said stop your frog fouling',\n",
              " 'i cleared up after him but it left a slimy mark',\n",
              " 'the other man slipped on it']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:19:21.545111Z",
          "iopub.execute_input": "2023-08-27T10:19:21.545958Z",
          "iopub.status.idle": "2023-08-27T10:19:21.707127Z",
          "shell.execute_reply.started": "2023-08-27T10:19:21.545924Z",
          "shell.execute_reply": "2023-08-27T10:19:21.706079Z"
        },
        "trusted": true,
        "id": "gXKaNn4CTgEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(f\"Vocabulary size: {vocab_size}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:19:21.708346Z",
          "iopub.execute_input": "2023-08-27T10:19:21.709338Z",
          "iopub.status.idle": "2023-08-27T10:19:21.714328Z",
          "shell.execute_reply.started": "2023-08-27T10:19:21.709309Z",
          "shell.execute_reply": "2023-08-27T10:19:21.713238Z"
        },
        "trusted": true,
        "id": "5Mbpr3wQTgEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df485b08-2f3d-4f22-c666-595911940374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 11747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_grams = []\n",
        "max_sequence_len = 0\n",
        "\n",
        "for sentence in corpus:\n",
        "    # convert sentence to tokens\n",
        "    tokens = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    for i in range(2, len(tokens)+1):\n",
        "        # extract n-gram\n",
        "        n_gram = tokens[:i]\n",
        "        # save n-gram\n",
        "        n_grams.append(n_gram)\n",
        "        # calculate maximum sequence length\n",
        "        if len(n_gram) > max_sequence_len:\n",
        "            max_sequence_len = len(n_gram)\n",
        "\n",
        "print(f\"Number of n-grams: {len(n_grams)}\")\n",
        "print(f\"Maximum n-gram length: {max_sequence_len}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:19:21.715921Z",
          "iopub.execute_input": "2023-08-27T10:19:21.716585Z",
          "iopub.status.idle": "2023-08-27T10:19:21.913115Z",
          "shell.execute_reply.started": "2023-08-27T10:19:21.716534Z",
          "shell.execute_reply": "2023-08-27T10:19:21.912094Z"
        },
        "trusted": true,
        "id": "HX6ivAlhTgEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e30d051-fb5a-4d0d-98ca-e1e1ed16abd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of n-grams: 55930\n",
            "Maximum n-gram length: 166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n_gram in n_grams[:10]:\n",
        "    print(n_gram)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:19:21.914519Z",
          "iopub.execute_input": "2023-08-27T10:19:21.915191Z",
          "iopub.status.idle": "2023-08-27T10:19:21.921402Z",
          "shell.execute_reply.started": "2023-08-27T10:19:21.915155Z",
          "shell.execute_reply": "2023-08-27T10:19:21.920224Z"
        },
        "trusted": true,
        "id": "LOqaCDIWTgEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a93499-0af7-47dd-9f23-49dc84b9d8af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8, 38]\n",
            "[8, 38, 5]\n",
            "[8, 38, 5, 2903]\n",
            "[8, 38, 5, 2903, 30]\n",
            "[26, 91]\n",
            "[26, 91, 30]\n",
            "[26, 91, 30, 580]\n",
            "[26, 91, 30, 580, 99]\n",
            "[26, 91, 30, 580, 99, 76]\n",
            "[26, 91, 30, 580, 99, 76, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pad n-grams"
      ],
      "metadata": {
        "id": "asFR69UKTgEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded_n_grams = np.array(pad_sequences(n_grams, maxlen=100, padding=\"pre\", truncating=\"pre\"))\n",
        "\n",
        "padded_n_grams.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:19:21.925674Z",
          "iopub.execute_input": "2023-08-27T10:19:21.926098Z",
          "iopub.status.idle": "2023-08-27T10:19:22.187048Z",
          "shell.execute_reply.started": "2023-08-27T10:19:21.926065Z",
          "shell.execute_reply": "2023-08-27T10:19:22.186035Z"
        },
        "trusted": true,
        "id": "PgPz-BvjTgEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4891ab-e093-4105-d08a-7ab004b63629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55930, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in padded_n_grams[:3]:\n",
        "    print(seq)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:19:22.188487Z",
          "iopub.execute_input": "2023-08-27T10:19:22.189155Z",
          "iopub.status.idle": "2023-08-27T10:19:22.196078Z",
          "shell.execute_reply.started": "2023-08-27T10:19:22.189118Z",
          "shell.execute_reply": "2023-08-27T10:19:22.19502Z"
        },
        "trusted": true,
        "id": "DxzxFdN4TgEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "231d73a2-de3e-45b5-c32f-21bed40c3e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  8 38]\n",
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  8 38  5]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    8   38\n",
            "    5 2903]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_n_grams[:, :-1]\n",
        "y = padded_n_grams[:, -1]\n",
        "\n",
        "print(f\"X: {X.shape}\")\n",
        "print(f\"y: {y.shape}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:19:22.197721Z",
          "iopub.execute_input": "2023-08-27T10:19:22.198438Z",
          "iopub.status.idle": "2023-08-27T10:19:22.207845Z",
          "shell.execute_reply.started": "2023-08-27T10:19:22.198405Z",
          "shell.execute_reply": "2023-08-27T10:19:22.206773Z"
        },
        "trusted": true,
        "id": "jzzn7k46TgEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50afd429-7e3f-413a-8511-dfd159a71b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: (55930, 99)\n",
            "y: (55930,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encode y\n",
        "\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "print(f\"y: {y.shape}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:19:22.20939Z",
          "iopub.execute_input": "2023-08-27T10:19:22.209997Z",
          "iopub.status.idle": "2023-08-27T10:19:22.363865Z",
          "shell.execute_reply.started": "2023-08-27T10:19:22.209962Z",
          "shell.execute_reply": "2023-08-27T10:19:22.362633Z"
        },
        "trusted": true,
        "id": "LucHOUzQTgEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8afba9b-426c-45d6-fc6f-b8fd75d73ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y: (55930, 11747)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "model = tf.keras.Sequential([\n",
        "    Embedding(vocab_size, 300, input_length=99),\n",
        "    Bidirectional(LSTM(150, return_sequences = True)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(100),\n",
        "    Dense(vocab_size/2, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    Dense(vocab_size, activation='softmax'),\n",
        "])\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:19:22.365517Z",
          "iopub.execute_input": "2023-08-27T10:19:22.366207Z",
          "iopub.status.idle": "2023-08-27T10:19:22.663098Z",
          "shell.execute_reply.started": "2023-08-27T10:19:22.366168Z",
          "shell.execute_reply": "2023-08-27T10:19:22.66227Z"
        },
        "trusted": true,
        "id": "dJyo-wspTgEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3eec70e-ba6a-4790-cb7e-bf7094408232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 99, 300)           3524100   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 99, 300)           541200    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 99, 300)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               160400    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5873)              593173    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 11747)             69001878  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 73820751 (281.60 MB)\n",
            "Trainable params: 73820751 (281.60 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X,\n",
        "    y,\n",
        "    epochs=150,\n",
        "    batch_size=128,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=20)\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:19:22.664459Z",
          "iopub.execute_input": "2023-08-27T10:19:22.664833Z",
          "iopub.status.idle": "2023-08-27T10:34:50.891807Z",
          "shell.execute_reply.started": "2023-08-27T10:19:22.664797Z",
          "shell.execute_reply": "2023-08-27T10:34:50.890538Z"
        },
        "trusted": true,
        "id": "KIFpLd2WTgEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f030328a-a805-4e5d-ee28-c0ec9270730b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "437/437 [==============================] - 58s 114ms/step - loss: 7.4318 - accuracy: 0.0640\n",
            "Epoch 2/150\n",
            "437/437 [==============================] - 35s 79ms/step - loss: 6.9483 - accuracy: 0.0817\n",
            "Epoch 3/150\n",
            "437/437 [==============================] - 33s 75ms/step - loss: 6.6376 - accuracy: 0.0948\n",
            "Epoch 4/150\n",
            "437/437 [==============================] - 32s 73ms/step - loss: 6.3953 - accuracy: 0.1062\n",
            "Epoch 5/150\n",
            "437/437 [==============================] - 32s 73ms/step - loss: 6.1858 - accuracy: 0.1146\n",
            "Epoch 6/150\n",
            "437/437 [==============================] - 32s 73ms/step - loss: 5.9874 - accuracy: 0.1212\n",
            "Epoch 7/150\n",
            "437/437 [==============================] - 31s 72ms/step - loss: 5.8009 - accuracy: 0.1276\n",
            "Epoch 8/150\n",
            "437/437 [==============================] - 32s 73ms/step - loss: 5.6207 - accuracy: 0.1345\n",
            "Epoch 9/150\n",
            "437/437 [==============================] - 33s 75ms/step - loss: 5.4429 - accuracy: 0.1433\n",
            "Epoch 10/150\n",
            "437/437 [==============================] - 32s 72ms/step - loss: 5.2685 - accuracy: 0.1511\n",
            "Epoch 11/150\n",
            "437/437 [==============================] - 31s 72ms/step - loss: 5.0901 - accuracy: 0.1593\n",
            "Epoch 12/150\n",
            "437/437 [==============================] - 32s 73ms/step - loss: 4.9088 - accuracy: 0.1689\n",
            "Epoch 13/150\n",
            "437/437 [==============================] - 32s 73ms/step - loss: 4.7293 - accuracy: 0.1792\n",
            "Epoch 14/150\n",
            "437/437 [==============================] - 32s 73ms/step - loss: 4.5515 - accuracy: 0.1931\n",
            "Epoch 15/150\n",
            "437/437 [==============================] - 31s 72ms/step - loss: 4.3751 - accuracy: 0.2105\n",
            "Epoch 16/150\n",
            "437/437 [==============================] - 32s 72ms/step - loss: 4.2015 - accuracy: 0.2289\n",
            "Epoch 17/150\n",
            "437/437 [==============================] - 32s 73ms/step - loss: 4.0360 - accuracy: 0.2496\n",
            "Epoch 18/150\n",
            "437/437 [==============================] - 32s 73ms/step - loss: 3.8674 - accuracy: 0.2728\n",
            "Epoch 19/150\n",
            "437/437 [==============================] - 31s 72ms/step - loss: 3.7099 - accuracy: 0.2981\n",
            "Epoch 20/150\n",
            "437/437 [==============================] - 31s 72ms/step - loss: 3.5627 - accuracy: 0.3224\n",
            "Epoch 21/150\n",
            "437/437 [==============================] - 31s 72ms/step - loss: 3.4208 - accuracy: 0.3474\n",
            "Epoch 22/150\n",
            "437/437 [==============================] - 31s 72ms/step - loss: 3.2861 - accuracy: 0.3711\n",
            "Epoch 23/150\n",
            "437/437 [==============================] - 31s 72ms/step - loss: 3.1613 - accuracy: 0.3930\n",
            "Epoch 24/150\n",
            "437/437 [==============================] - 32s 72ms/step - loss: 3.0415 - accuracy: 0.4172\n",
            "Epoch 25/150\n",
            "437/437 [==============================] - 31s 72ms/step - loss: 2.9311 - accuracy: 0.4391\n",
            "Epoch 26/150\n",
            "437/437 [==============================] - 31s 72ms/step - loss: 2.8321 - accuracy: 0.4584\n",
            "Epoch 27/150\n",
            "437/437 [==============================] - 31s 72ms/step - loss: 2.7344 - accuracy: 0.4793\n",
            "Epoch 28/150\n",
            "437/437 [==============================] - 31s 72ms/step - loss: 2.6420 - accuracy: 0.4958\n",
            "Epoch 29/150\n",
            "437/437 [==============================] - 31s 71ms/step - loss: 2.5602 - accuracy: 0.5098\n",
            "Epoch 30/150\n",
            "437/437 [==============================] - 31s 72ms/step - loss: 2.4804 - accuracy: 0.5275\n",
            "Epoch 31/150\n",
            "437/437 [==============================] - 31s 72ms/step - loss: 2.4053 - accuracy: 0.5428\n",
            "Epoch 32/150\n",
            "437/437 [==============================] - 31s 72ms/step - loss: 2.3343 - accuracy: 0.5585\n",
            "Epoch 33/150\n",
            "437/437 [==============================] - 32s 72ms/step - loss: 2.2655 - accuracy: 0.5714\n",
            "Epoch 34/150\n",
            "437/437 [==============================] - 31s 71ms/step - loss: 2.2051 - accuracy: 0.5845\n",
            "Epoch 35/150\n",
            "140/437 [========>.....................] - ETA: 21s - loss: 2.0531 - accuracy: 0.6179"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "bP6jDTncRghw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "wuXBR4BZaSQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot learning curves"
      ],
      "metadata": {
        "id": "Qpl1tHhQTgEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.history.history\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.title(\"Loss\")\n",
        "plt.plot(hist[\"loss\"])\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.title(\"Accuracy\")\n",
        "plt.plot(hist[\"accuracy\"], color=\"orange\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:34:50.893677Z",
          "iopub.execute_input": "2023-08-27T10:34:50.894392Z",
          "iopub.status.idle": "2023-08-27T10:34:51.4436Z",
          "shell.execute_reply.started": "2023-08-27T10:34:50.894352Z",
          "shell.execute_reply": "2023-08-27T10:34:51.442626Z"
        },
        "trusted": true,
        "id": "8RQLtbDpTgEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Poetry generation"
      ],
      "metadata": {
        "id": "y00dSG_0TgEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(seed_text, next_words):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=99, padding=\"pre\")\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0))\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    print(seed_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:36:09.057122Z",
          "iopub.execute_input": "2023-08-27T10:36:09.057496Z",
          "iopub.status.idle": "2023-08-27T10:36:09.064972Z",
          "shell.execute_reply.started": "2023-08-27T10:36:09.057466Z",
          "shell.execute_reply": "2023-08-27T10:36:09.063607Z"
        },
        "trusted": true,
        "id": "8YMumiLHTgEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate(\"Nature\", 50)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-08-27T10:36:09.646428Z",
          "iopub.execute_input": "2023-08-27T10:36:09.647883Z",
          "iopub.status.idle": "2023-08-27T10:36:20.490532Z",
          "shell.execute_reply.started": "2023-08-27T10:36:09.647837Z",
          "shell.execute_reply": "2023-08-27T10:36:20.489402Z"
        },
        "trusted": true,
        "id": "Ym1vdBzBTgEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_poem(genre, title, next_words=100):\n",
        "\n",
        "    seed_text = genre + \" \" + title  # Combine genre and title for the seed text\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=99, padding=\"pre\")\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    print(seed_text)\n",
        "\n",
        "# Example usage:\n",
        "# First, load your model (if it's not already in memory)\n",
        "model = load_model('model.h5')  # Adjust the path as needed\n",
        "\n",
        "# Generate a poem with a given genre and title\n",
        "generate_poem(\"Fairy-tales\", \"Tales from the Enchanted Forest\", 100)\n"
      ],
      "metadata": {
        "id": "loQZe6QtLKo-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}